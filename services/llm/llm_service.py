import json
import urllib.parse
import requests
import boto3
import os
import re
from datetime import datetime, timezone
from common.config import get_config
from common.utils import invoke_bedrock_nova, cors_headers, cors_response
from slack_sdk import WebClient

# Lambda í™˜ê²½ì—ì„œ íš¨ìœ¨ì ì¸ ì¬ì‚¬ìš©ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ìºì‹±
client = None

# í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ì €ì¥ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
client_cache = {}

# DynamoDB ì„¤ì • (ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”)
try:
    CONFIG = get_config()
    CHAT_HISTORY_TABLE = CONFIG.get('db', {}).get('chat_history_table')

    if CHAT_HISTORY_TABLE:
        dynamodb = boto3.resource('dynamodb')
        chat_table = dynamodb.Table(CHAT_HISTORY_TABLE)
        print(f"DynamoDB í…Œì´ë¸” ì—°ê²° ì„±ê³µ: {CHAT_HISTORY_TABLE}")
    else:
        chat_table = None
        print("DynamoDB í…Œì´ë¸” ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ìºì‹± ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
except Exception as e:
    print(f"DynamoDB ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
    chat_table = None


def get_anthropic_models():
    """
    Anthropic APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒ

    Returns:
        list: ëª¨ë¸ ì •ë³´ ë°°ì—´ (display_nameê³¼ idë§Œ í¬í•¨)
    """
    try:
        CONFIG = get_config()
        anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY') or CONFIG.get('anthropic', {}).get('api_key')

        if not anthropic_api_key:
            print("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        headers = {
            "x-api-key": anthropic_api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }

        response = requests.get(
            "https://api.anthropic.com/v1/models",
            headers=headers
        )

        if response.status_code != 200:
            print(f"Anthropic Models API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return []

        models_data = response.json()
        models = models_data.get('data', [])

        # display_nameê³¼ idë§Œ ì¶”ì¶œí•˜ì—¬ ë°°ì—´ë¡œ ë°˜í™˜
        model_list = []
        for model in models:
            model_info = {
                "id": model.get("id", ""),
                "display_name": model.get("display_name", model.get("id", ""))
            }
            model_list.append(model_info)

        print(f"Anthropic ëª¨ë¸ {len(model_list)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        return model_list

    except Exception as e:
        print(f"Anthropic ëª¨ë¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []


def get_session_messages_as_array(session_id: str) -> list:
    """
    DynamoDBì—ì„œ ì„¸ì…˜ì˜ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ messages ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜´

    Args:
        session_id: ì±„íŒ… ì„¸ì…˜ ID

    Returns:
        messages ë°°ì—´ í˜•ì‹ì˜ ëŒ€í™” ê¸°ë¡
    """
    try:
        if not chat_table:
            print("DynamoDB í…Œì´ë¸”ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        response = chat_table.get_item(
            Key={'sessionId': session_id}
        )

        session = response.get('Item')
        if not session:
            print(f"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return []

        messages = session.get('messages', [])

        # ë©”ì‹œì§€ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        messages.sort(key=lambda x: x.get('timestamp', ''))

        # Claude/Anthropic API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_messages = []
        for msg in messages:
            sender = msg.get('sender', 'user')
            text = msg.get('text', '')

            if sender == 'user':
                formatted_messages.append({
                    "role": "user",
                    "content": text
                })
            elif sender == 'assistant':
                formatted_messages.append({
                    "role": "assistant",
                    "content": text
                })

        print(f"ì„¸ì…˜ {session_id}ì—ì„œ {len(formatted_messages)}ê°œ ë©”ì‹œì§€ë¥¼ ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë¡œë“œë¨")
        return formatted_messages

    except Exception as e:
        print(f"ì„¸ì…˜ ë©”ì‹œì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return []


def get_client(model_id: str = None):
    """
    MCP í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±
    ëª¨ë¸ IDë³„ë¡œ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìºì‹±
    """
    global client_cache

    # ê¸°ë³¸ ëª¨ë¸ ID ì„¤ì •
    model_id = model_id or 'claude-3-7-sonnet-20250219'

    # ìºì‹œì— í•´ë‹¹ ëª¨ë¸ IDì˜ í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if model_id not in client_cache:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ êµ¬ì„± ê°€ì ¸ì˜¤ê¸°
        CONFIG = get_config()
        mcp_url = os.environ.get('MCP_URL') or CONFIG.get('mcp', {}).get('function_url')

        # ì‚¬ìš©í•  í´ë¼ì´ì–¸íŠ¸ ìœ í˜• ê²°ì • (Bedrock ë˜ëŠ” Anthropic)
        use_anthropic = os.environ.get('USE_ANTHROPIC_API', 'true').lower() == 'true'

        if use_anthropic:
            # Anthropic API ì„¤ì •
            anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY') or CONFIG.get('anthropic', {}).get('api_key')

            # Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            from mcp_anthropic_client import AnthropicMCPClient
            client_cache[model_id] = AnthropicMCPClient(
                mcp_url=mcp_url,
                api_key=anthropic_api_key,
                model_id=model_id
            )
        else:
            # Bedrock ì„¤ì •
            mcp_token = os.environ.get('MCP_TOKEN', '')
            region = os.environ.get('AWS_REGION', 'us-east-1')

            # Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            from mcp_bedrock_client import BedrockMCPClient
            client_cache[model_id] = BedrockMCPClient(
                mcp_url=mcp_url,
                region=region,
                auth_token=mcp_token,
                model_id=model_id
            )

        # ì„¸ì…˜ ì´ˆê¸°í™” ë° ë„êµ¬ ë¡œë“œ
        client_cache[model_id].initialize()

        print(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸ ID: {model_id}")

    return client_cache[model_id]


def handle_llm1_with_mcp(body, origin):
    """
    MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ llm1 ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ë„êµ¬ ì‚¬ìš© ê³¼ì • ë° ê²°ê³¼ í¬í•¨
    ì„¸ì…˜ ê¸°ë°˜ ë©”ì‹œì§€ ìºì‹± ì§€ì› (ê°œì„ ëœ messages ë°°ì—´ ë°©ì‹)

    Args:
        body: ìš”ì²­ ë³¸ë¬¸
        origin: CORS origin

    Returns:
        ì‘ë‹µ ê°ì²´ (ë„êµ¬ ì‚¬ìš© ê³¼ì • ë° ê²°ê³¼ í¬í•¨)
    """
    try:
        # ìš”ì²­ ë°ì´í„° ì¶”ì¶œ
        user_input = body.get('question') or body.get('text') or body.get('input', {}).get('text', '')
        session_id = body.get('sessionId')
        is_cached = body.get('isCached', True)
        model_id = body.get('modelId')
        slack_user_id = body.get("user_id")

        print(f"=== ìš”ì²­ ë¶„ì„ ===")
        print(f"user_input: {user_input}")
        print(f"session_id: {session_id}")
        print(f"is_cached: {is_cached}")
        print(f"model_id: {model_id}")
        print(f"slack_user_id: {slack_user_id}")
        print(f"chat_table ìƒíƒœ: {chat_table is not None}")
        print(f"ì „ì²´ body: {json.dumps(body, ensure_ascii=False)}")

        if not user_input:
            return cors_response(400, {"error": "ì‚¬ìš©ì ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}, origin)


        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = """You are "AWS Cloud Agent" - AWS ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸. í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µ.

        <Tools>
        ê³„ì •ë¶„ì„: fetch_cloudwatch_logs_for_service("cloudtrail") â†’ analyze_log_groups_insights
        ë³´ì•ˆë¶„ì„: fetch_cloudwatch_logs_for_service("guardduty") â†’ analyze_log_groups_insights
        AWSë¬¸ì„œ: search_documentation â†’ recommend_documentation â†’ read_documentation
        ë¹„ìš©ë¶„ì„: get_detailed_breakdown_by_day
        ì‹œê°í™”: ìš”ì²­ì‹œ ì°¨íŠ¸ ìƒì„± í›„ ![ì œëª©](url) í‘œì‹œ

        <Rules>
        - ìµœì†Œ ë„êµ¬ë§Œ ì‚¬ìš©, ì¶©ë¶„í•œ ì •ë³´ í™•ë³´ì‹œ ì¦‰ì‹œ ë‹µë³€
        - Time zone: UTC+9
        - ì°¨íŠ¸ëŠ” ëª…ì‹œì  ìš”ì²­ì‹œì—ë§Œ ìƒì„±
        """

        # MCP í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        client = get_client(model_id)

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        question_time = datetime.now(timezone.utc)

        # ì„¸ì…˜ ê¸°ë°˜ ì²˜ë¦¬ (ê°œì„ ëœ ë°©ì‹ - messages ë°°ì—´ ì‚¬ìš©)
        if is_cached and session_id and chat_table:
            try:
                print(f"=== ì„¸ì…˜ ìºì‹± ëª¨ë“œ ì‹œì‘ (ê°œì„ ëœ ë°©ì‹) ===")
                print(f"ì„¸ì…˜ ID: {session_id}")

                # ì„¸ì…˜ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ messages ë°°ì—´ë¡œ ë¡œë“œ
                previous_messages = get_session_messages_as_array(session_id)

                if previous_messages:
                    print(f"=== íˆìŠ¤í† ë¦¬ ë°œê²¬ ===")
                    print(f"ë¡œë“œëœ ë©”ì‹œì§€ ìˆ˜: {len(previous_messages)}")

                    # ë©”ì‹œì§€ ìƒ˜í”Œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                    for i, msg in enumerate(previous_messages[-3:]):  # ë§ˆì§€ë§‰ 3ê°œë§Œ
                        print(f"ìµœê·¼ ë©”ì‹œì§€ {i + 1}: {msg.get('role')} - {msg.get('content', '')[:50]}...")

                    # ì´ì „ ëŒ€í™” + ìƒˆ ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬
                    response_text = client.process_user_input_with_history(
                        user_input,
                        system_prompt,
                        previous_messages
                    )
                else:
                    print("=== ì„¸ì…˜ ë©”ì‹œì§€ ì—†ìŒ ===")
                    print("ì¼ë°˜ ëª¨ë“œë¡œ ì²˜ë¦¬")
                    response_text = client.process_user_input(user_input, system_prompt)

            except Exception as e:
                print(f"=== ì„¸ì…˜ ìºì‹± ì˜¤ë¥˜ ===")
                print(f"ì˜¤ë¥˜: {str(e)}")
                print("ì¼ë°˜ ëª¨ë“œë¡œ í´ë°±")
                response_text = client.process_user_input(user_input, system_prompt)
        else:
            # ì¼ë°˜ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
            print("=== ì¼ë°˜ ëª¨ë“œ ===")
            print(f"is_cached: {is_cached}, session_id: {session_id}, chat_table: {chat_table is not None}")
            response_text = client.process_user_input(user_input, system_prompt)

        # ë””ë²„ê·¸ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ì¶”ê°€ëœ get_debug_log ë©”ì„œë“œ ì‚¬ìš©)
        debug_log = client.get_debug_log() if hasattr(client, "get_debug_log") else []

        # ë„êµ¬ ì‚¬ìš© ë° ì‚¬ê³  ê³¼ì • ì •ë¦¬
        tools_used = []
        reasoning_steps = []
        token_usage = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}

        for entry in debug_log:
            entry_type = entry.get("type")

            if entry_type == "model_reasoning":
                reasoning_steps.append({
                    "content": entry.get("content"),
                    "input_tokens": entry.get("input_tokens", 0),
                    "output_tokens": entry.get("output_tokens", 0),
                    "timestamp": entry.get("timestamp")
                })
            elif entry_type == "tool_result":
                tools_used.append({
                    "tool_name": entry.get("tool_name"),
                    "input": entry.get("input")
                })
            elif entry_type in ["final_response", "final_response_with_history"]:
                # ìµœì¢… ì‘ë‹µì—ì„œ ì´ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
                token_usage = {
                    "input_tokens": entry.get("input_tokens", 0),
                    "output_tokens": entry.get("output_tokens", 0),
                }
                print(f"ìµœì¢… í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ: {token_usage}")

        # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        reasoning_steps.sort(key=lambda x: x.get("timestamp", 0))
        tools_used.sort(key=lambda x: x.get("timestamp", 0))

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ëŠ” ì œê±°
        for step in reasoning_steps:
            if "timestamp" in step:
                del step["timestamp"]

        for tool in tools_used:
            if "timestamp" in tool:
                del tool["timestamp"]

        reasoning_content = []
        for step in reasoning_steps:
            reasoning_content.append({
                "content": step.get("content"),
                "input_tokens": step.get("input_tokens", 0),
                "output_tokens": step.get("output_tokens", 0)
            })

        debug_info = {
            "tools_used": tools_used,
            "reasoning": reasoning_content,
            "session_cached": is_cached and session_id is not None and chat_table is not None,
            "session_id": session_id if is_cached else None,
            "token_usage": token_usage
        }

        # ì‘ë‹µ ì‹œê°„ ê¸°ë¡ ë° ê²½ê³¼ ì‹œê°„ ê³„ì‚°
        response_time = datetime.now(timezone.utc)
        elapsed = response_time - question_time
        minutes, seconds = divmod(elapsed.total_seconds(), 60)
        elapsed_str = f"{int(minutes)}ë¶„ {int(seconds)}ì´ˆ" if minutes else f"{int(seconds)}ì´ˆ"

        # ìµœì¢… ê²°ê³¼ë¥¼ Slackìœ¼ë¡œ ì „ì†¡
        if slack_user_id:
            send_slack_dm(slack_user_id, response_text)

        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜ (ë„êµ¬ ì‚¬ìš© ê³¼ì • ë° ê²°ê³¼ í¬í•¨)
        return cors_response(200, {
            "answer": response_text,
            "elapsed_time": elapsed_str,
            "inference": debug_info  # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
        }, origin)

    except Exception as e:
        print(f"MCP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return cors_response(500, {
            "error": "MCP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "answer": str(e)
        }, origin)


def get_table_registry():
    dynamodb = boto3.resource("dynamodb")
    table_name = os.environ.get("ATHENA_TABLE_REGISTRY_TABLE")
    table = dynamodb.Table(table_name)
    response = table.scan()
    return {item["log_type"]: item for item in response.get("Items", [])}


def call_mcp_service(user_question):
    CONFIG = get_config()
    payload = {
        "input": {
            "text": user_question
        }
    }
    response = requests.post(CONFIG['mcp']['function_url'], json=payload)
    return response.json()


def trans_eng_to_kor(text):
    prompt = f"""
You are a professional translator.
The following text may include a list of citations in dictionary-like format.
Translate only the explanation sentences into Korean.

- Remove any technical field names like 'rank_order', 'context', 'title', 'url'.
- Preserve any URLs and titles.
- Do NOT translate URLs or titles.
- Format the result cleanly so that each citation appears as:

í•œêµ­ì–´ ë²ˆì—­ëœ ì„¤ëª…
ì›ë˜ ì œëª©
ì›ë˜ URL

Translate the text below accordingly.
Only Generate Translate.

Text to translate:
{text}
"""
    response = invoke_bedrock_nova(prompt)
    trans_response = response["output"]["message"]["content"][0]["text"]
    return trans_response


def build_llm1_prompt(user_input):
    registry = get_table_registry()
    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
    if "cloudtrail" in registry and "guardduty" in registry:
        ct_table = registry["cloudtrail"]["table_name"]
        ct_location = registry["cloudtrail"]["s3_path"]
        gd_table = registry["guardduty"]["table_name"]
        gd_location = registry["guardduty"]["s3_path"]

        # í…Œì´ë¸” ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        tables_info = f"""
Available tables:
1. {ct_table} - CloudTrail logs at {ct_location}
2. {gd_table} - GuardDuty logs at {gd_location}
        """
    else:
        # í…Œì´ë¸” ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ê¸°ë³¸ê°’
        print("WARNING: Table registry information missing")
        tables_info = """
Available tables:
1. cloudtrail_logs - CloudTrail logs 
2. guardduty_logs - GuardDuty logs
        """

    return f'''
You are a SQL generation expert for AWS Athena (Presto SQL).
Generate ONLY SQL code that is valid in Athena with no explanation.

{tables_info}

Task:
Convert the following natural language question into an SQL query using the available tables.

Model Instructions:
    # Output Requirements:
        - Return only the SQL code, no explanations.
        - If filtering by date, use the `"partition_date"` field only.
        - If counting unique users, use `COUNT(DISTINCT userIdentity.userName)`.
        - If you use a field that is not aggregated (like username), you must include it in the GROUP BY clause.
        - Avoid using non-aggregated expressions in SELECT unless they are grouped.
        - If filtering by user name, exclude records where useridentity.username is null or empty string.
	    - Use IS NOT NULL AND useridentity.username != '' to ensure only valid user names are considered.
	    - If partition_date is a string like yyyy/MM/dd, use date_parse(partition_date, '%Y/%m/%d') to convert it before filtering by date.


User Question:
{user_input}
'''


def build_llm2_prompt(user_input, query_result):
    return f'''
You are an assistant that provides clear and accurate natural language explanations based on database query results.

Task:
Generate a human-readable answer based on the original user question and the SQL query result.

Original User Question:
{user_input}

SQL Query Result (as JSON):
{json.dumps(query_result, indent=2)}

Instructions:
- Be specific using the data.
- Use concise, professional language.
- Answer in Korean
- Do not ask user for clarification.
- If the original query includes grouping or aggregation, make sure to reflect the logic accurately.
- Highlight any anomalies or low counts if the data is sparse.
'''


def parse_body(event):
    content_type = event.get("headers", {}).get("Content-Type", "") or \
                   event.get("headers", {}).get("content-type", "")

    raw_body = event.get("body") or ""

    if "application/json" in content_type:
        try:
            return json.loads(raw_body)
        except json.JSONDecodeError:
            print("â— ì˜ëª»ëœ JSON body:", raw_body)
            return {}

    elif "application/x-www-form-urlencoded" in content_type:
        return {k: v[0] for k, v in urllib.parse.parse_qs(raw_body).items()}

    return {}


def call_create_table_cloudtrail():
    CONFIG = get_config()
    payload = {
        "log_type": "cloudtrail",
        "s3_path": "s3://wga-cloudtrail-2/AWSLogs/339712974607/CloudTrail/us-east-1/",
        "table_name": "cloudtrail_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload)


def call_create_table_guardduty():
    CONFIG = get_config()
    payload = {
        "log_type": "guardduty",
        "s3_path": "s3://wga-guardduty-logs/guardduty-logs/",
        "table_name": "guardduty_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload)


def call_execute_query(sql_query):
    CONFIG = get_config()
    wrapper_payload = {
        "query": sql_query
    }
    res = requests.post(f'{CONFIG['api']['endpoint']}/execute-query',
                        json=wrapper_payload)  # Athena ì¿¼ë¦¬ ì‹¤í–‰ API URLì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”
    return res.json()

import re

def markdown_to_slack_mrkdwn(text):
    # í—¤ë”ë¥¼ ë³¼ë“œë¡œ ì¹˜í™˜ (ëª¨ë“  í—¤ë” ë ˆë²¨)
    text = re.sub(r'^(#{1,6})\s*(.*)', r'*\2*', text, flags=re.MULTILINE)

    # ë³¼ë“œ: **í…ìŠ¤íŠ¸** â†’ *í…ìŠ¤íŠ¸*
    text = re.sub(r'\*\*(\S(.*?\S)?)\*\*', r'*\1*', text)

    # ì´íƒ¤ë¦­: *í…ìŠ¤íŠ¸* ë˜ëŠ” _í…ìŠ¤íŠ¸_ â†’ _í…ìŠ¤íŠ¸_
    text = re.sub(r'\*(\S(.*?\S)?)\*', r'_\1_', text)

    # ì·¨ì†Œì„ : ~~í…ìŠ¤íŠ¸~~ â†’ ~í…ìŠ¤íŠ¸~
    text = re.sub(r'~~(.*?)~~', r'~\1~', text)

    # ì¸ë¼ì¸ ì½”ë“œ(`code`) ë° ì½”ë“œë¸”ë¡(``````)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

    # ë§í¬: [í…ìŠ¤íŠ¸](URL) â†’ <URL|í…ìŠ¤íŠ¸>
    text = re.sub(r'\[(.*?)\]\((.*?)\)', r'<\2|\1>', text)

    # í‘œ: Slack mrkdwnì—ì„œ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
    text = re.sub(r'\|.*\|', '', text)

    # ë¸”ë¡ ì¸ìš©: > ì¸ìš©ë¬¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

    # ì´ë¯¸ì§€: Slack mrkdwnì—ì„œ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
    text = re.sub(r'!\[(.*?)\]\((.*?)\)', '', text)

    return text


def send_slack_dm(user_id, response_text):
    CONFIG = get_config()
    client = WebClient(token=CONFIG['slackbot']['token'])  # ì—¬ê¸°ì— Slack Bot Token
    response_text = markdown_to_slack_mrkdwn(response_text)

    response = client.chat_postMessage(
        channel=user_id,  # ì—¬ê¸°ì„œ user_id ê·¸ëŒ€ë¡œ DM ì±„ë„ë¡œ ì‚¬ìš© ê°€ëŠ¥
        blocks=[
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": (
                        f"ğŸ§  ë¶„ì„ ê²°ê³¼:\n{response_text}"
                    )
                }
            }
        ]
    )
    if not response["ok"]:
        print("âŒ Slack ë©”ì‹œì§€ ì‹¤íŒ¨ ì‚¬ìœ :", response["error"])
    return response


def handle_llm1_request(body, CONFIG, origin):
    question_time = datetime.now(timezone.utc)
    user_question = body.get("text")
    slack_user_id = body.get("user_id")

    if not user_question:
        return cors_response(400, {"error": "request bodyì— 'text'ê°€ ì—†ìŒ."}, origin)

    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸: {user_question}")

    # í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ í™•ì¸
    registry = get_table_registry()
    print(f"í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬: {registry}")

    # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    classification_prompt = f"""
    Determine whether the following questions should be queried data from the AWS CloudTrail or GuardDuty logs, 
    look up AWS official documents or information, or are irrelevant to what was previously described.

    Possible response:
    - "QUERY":  
    Questions that request data analysis based on "CloudTrail" or "GuardDuty" logs.  
    These questions typically require SQL generation to query structured logs.  
    Example patterns:
        â€¢ Who accessed S3 yesterday?  
        â€¢ Show login failures in the last 24 hours  
        â€¢ What user deleted EC2 instances recently?  
    MUST involve:  
        - eventName, sourceIPAddress, userIdentity, region, or timestamp  
        - keywords like: find, show, list, get, analyze, from logs  

    - "DOCUMENT":  
    Questions that ask for explanations, descriptions, or definitions of AWS-related services, fields, concepts, or syntax.  
    These questions do not require data querying, but rather reference AWS documentation.  
    Example patterns:  
        â€¢ What does GuardDuty severity mean?  
        â€¢ How does partitioning work in Athena?  
        â€¢ Explain sourceIPAddress in CloudTrail  
    May include:  
        - questions starting with what / how / why / explain  
        - terminology clarification (e.g., difference between LIMIT and OFFSET)

    - "Boundary":
    Questions that are borderline between "QUERY" and "DOCUMENT".
    These questions may require both data querying and documentation reference. 

    - "USELESS":  
    Questions that are irrelevant to AWS log analysis or documentation.  
    This includes greetings, personal opinions, jokes, or off-topic inquiries.  
    Example patterns:  
        â€¢ Hello  
        â€¢ Who made you?  
        â€¢ Tell me a joke  
        â€¢ I love AWS


    Questions: {user_question}

    Result(QUERY, DOCUMENT, BOUNDARY, or USELESS only):
    """

    classification_result = invoke_bedrock_nova(classification_prompt)
    decision = classification_result["output"]["message"]["content"][0]["text"].strip()
    print(f"ë¶„ë¥˜ ê²°ê³¼: {decision}")

    # 2ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…
    if "QUERY" in decision:
        # ê¸°ì¡´ ë¡œì§: SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
        prompt = build_llm1_prompt(user_question)
        sql_query = invoke_bedrock_nova(prompt)
        raw_text = sql_query["output"]["message"]["content"][0]["text"]

        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
        cleaned = raw_text.strip().removeprefix("```sql").removesuffix("```").strip()

        call_create_table_cloudtrail()
        call_create_table_guardduty()
        cleaned_query_result = call_execute_query(cleaned)

        llm2_response = requests.post(
            f"{CONFIG['api']['endpoint']}/llm2",
            json={
                "question": user_question,
                "result": cleaned_query_result
            }
        )

        try:
            llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
            if isinstance(llm2_answer, str):
                text_answer = llm2_answer
            else:
                text_answer = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text",
                                                                                                           "[ë‹µë³€ ì—†ìŒ]")
        except Exception as parse_error:
            print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
            text_answer = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"

    elif "DOCUMENT" in decision:  # "DOCUMENT"ì¸ ê²½ìš°
        # MCP Lambda í˜¸ì¶œ
        mcp_response = call_mcp_service(user_question)
        text_answer = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
        text_answer = trans_eng_to_kor(text_answer)

    elif "BOUNDARY" in decision:
        # ê¸°ì¡´ ë¡œì§: SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
        prompt = build_llm1_prompt(user_question)
        sql_query = invoke_bedrock_nova(prompt)
        raw_text = sql_query["output"]["message"]["content"][0]["text"]

        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
        cleaned = raw_text.strip().removeprefix("```sql").removesuffix("```").strip()

        call_create_table_cloudtrail()
        call_create_table_guardduty()
        cleaned_query_result = call_execute_query(cleaned)

        llm2_response = requests.post(
            f"{CONFIG['api']['endpoint']}/llm2",
            json={
                "question": user_question,
                "result": cleaned_query_result
            }
        )

        try:
            llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
            if isinstance(llm2_answer, str):
                text_answer_q = llm2_answer
            else:
                text_answer_q = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text",
                                                                                                             "[ë‹µë³€ ì—†ìŒ]")
        except Exception as parse_error:
            print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
            text_answer_q = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"

        # MCP Lambda í˜¸ì¶œ
        mcp_response = call_mcp_service(user_question)
        text_answer_d = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
        text_answer_d = trans_eng_to_kor(text_answer_d)

        text_answer = f"""
        [1] ğŸ“Š ë¡œê·¸ ë¶„ì„ ê²°ê³¼:
        {text_answer_q}

        [2] ğŸ“˜ ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ ì„¤ëª…:
        {text_answer_d}
        """

    else:
        text_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ìš´ì˜ì •ë³´ í˜¹ì€ ë©”ë‰´ì–¼ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."

    response_time = datetime.now(timezone.utc)
    elapsed = response_time - question_time
    minutes, seconds = divmod(elapsed.total_seconds(), 60)
    # í¬ë§·
    elapsed_str = f"{int(minutes)}ë¶„ {int(seconds)}ì´ˆ" if minutes else f"{int(seconds)}ì´ˆ"

    return cors_response(200, {
        "status": "ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ",
        "answer": text_answer + f"\n\nì†Œìš”ì‹œê°„: {elapsed_str}"
    }, origin)


def handle_llm2_request(body, CONFIG, origin):
    user_question = body.get("question")
    query_result = body.get("result")

    if not user_question or not query_result:
        return cors_response(400, {"error": "request bodyì— 'question' ì´ë‚˜ 'result'ê°€ ì—†ìŒ."}, origin)

    prompt = build_llm2_prompt(user_question, query_result)
    answer = invoke_bedrock_nova(prompt)

    return cors_response(200, {"answer": answer}, origin)