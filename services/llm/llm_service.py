import json
import urllib.parse
import requests
import boto3
import os
import time
from common.config import get_config
from common.utils import invoke_bedrock_nova, cors_headers, cors_response
from slack_sdk import WebClient

# CloudWatch Logs client
def get_logs_client():
    return boto3.client('logs', region_name=os.environ.get('AWS_REGION'))

# 1) Log Group ëª©ë¡ ì¡°íšŒ ê¸°ëŠ¥
def list_log_groups(prefix=None, limit=50):
    """
    í˜„ì¬ ê³„ì •ì˜ CloudWatch Log Groups ëª©ë¡ì„ ë°˜í™˜
      - prefix: ì´ë¦„ ì ‘ë‘ì–´ë¡œ í•„í„°ë§ (ì—†ìœ¼ë©´ ì „ì²´)
      - limit: í˜ì´ì§€ë‹¹ ì¡°íšŒ ê°œìˆ˜
    """
    logs = get_logs_client()
    paginator = logs.get_paginator('describe_log_groups')
    params = {'limit': limit}
    if prefix:
        params['logGroupNamePrefix'] = prefix

    groups = []
    for page in paginator.paginate(**params):
        for g in page.get('logGroups', []):
            groups.append({
                'logGroupName': g['logGroupName'],
                'creationTime': g['creationTime'],
                'retentionInDays': g.get('retentionInDays')
            })
    print(f"Log groups: {groups}")
    return groups

# 2) CloudWatch Logs Insights ì¿¼ë¦¬ ê¸°ëŠ¥
def call_insights_query(log_group, query_string, start_time, end_time, limit=100):
    """
    CloudWatch Logs Insights ì¿¼ë¦¬ ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜
    """
    logs = get_logs_client()
    resp = logs.start_query(
        logGroupNames=[log_group],
        startTime=start_time,
        endTime=end_time,
        queryString=query_string,
        limit=limit
    )
    query_id = resp['queryId']

    # ì™„ë£Œ ëŒ€ê¸°
    while True:
        status_resp = logs.get_query_results(queryId=query_id)
        status = status_resp['status']
        if status in ('Complete', 'Failed', 'Cancelled'):
            print(f">>> ì¿¼ë¦¬ ìƒíƒœ: {status}")
            break
        time.sleep(1)

    results = status_resp.get('results', [])
    # Debug: raw ê²°ê³¼ ì¶œë ¥
    print(">>> call_insights_query ì›ë³¸ ê²°ê³¼:")
    print(json.dumps(results, indent=2, ensure_ascii=False))

    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì²´ ë¡œì§
    if not results:
        print(f">>> ë¹ˆ ê²°ê³¼ ")

    return results

def get_table_registry():
    dynamodb = boto3.resource("dynamodb")
    table_name = os.environ.get("ATHENA_TABLE_REGISTRY_TABLE")
    table = dynamodb.Table(table_name)
    response = table.scan()
    return {item["log_type"]: item for item in response.get("Items", [])}

def call_mcp_service(user_question):
    CONFIG = get_config()
    payload = {
        "input": {
            "text": user_question
        }
    }
    response = requests.post(CONFIG['mcp']['function_url'], json=payload)
    return response.json()

def build_llm1_prompt(user_input):
    registry = get_table_registry()
    if "cloudtrail" in registry and "guardduty" in registry:
        ct_table = registry["cloudtrail"]["table_name"]
        ct_location = registry["cloudtrail"]["s3_path"]
        gd_table = registry["guardduty"]["table_name"]
        gd_location = registry["guardduty"]["s3_path"]
        tables_info = f"""
Available tables:
1. {ct_table} - CloudTrail logs at {ct_location}
2. {gd_table} - GuardDuty logs at {gd_location}
        """
    else:
        print("WARNING: Table registry information missing")
        tables_info = """
Available tables:
1. cloudtrail_logs - CloudTrail logs 
2. guardduty_logs - GuardDuty logs
        """

    return f'''
You are a SQL generation expert for AWS Athena (Presto SQL).
Generate ONLY SQL code that is valid in Athena with no explanation.

{tables_info}

Task:
Convert the following natural language question into an SQL query using the available tables.

Decision step (MUST):
- If the request is about CloudTrail / GuardDuty / AWS ë³´ì•ˆ ë¡œê·¸ ë¶„ì„, output ONLY valid Athena SQL.
- Otherwise (greetings, DevOps ê°œë… ì„¤ëª…, ë‚ ì”¨ ë“±) output EXACTLY: ###IGNORED###

Model Instructions:
    # Output Requirements:
        - Return only the SQL code, no explanations.
        - If filtering by date, use the `"partition_date"` field only.
        - If counting unique users, use `COUNT(DISTINCT userIdentity.userName)`.
        - If you use a field that is not aggregated (like username), you must include it in the GROUP BY clause.
        - Avoid using non-aggregated expressions in SELECT unless they are grouped.
        - If filtering by user name, exclude records where useridentity.username is null or empty string.
        - Use IS NOT NULL AND useridentity.username != '' to ensure only valid user names are considered.
        - If partition_date is a string like yyyy/MM/dd, use date_parse(partition_date, '%Y/%m/%d') to convert it before filtering by date.

User Question:
{user_input}
'''

def build_llm2_prompt(user_input, query_result):
    return f'''
You are an assistant that provides clear and accurate natural language explanations based on database query results.

Task:
Generate a human-readable answer based on the original user question and the SQL query result.

# Expections(MUST):
- If the SQL query result is empty or ###IGNORED###, respond directly : "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ë³´ì•ˆ ë¡œê·¸ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."

Original User Question:
{user_input}

SQL Query Result (as JSON):
{json.dumps(query_result, indent=2)}

Instructions:
- Be specific using the data.
- Use concise, professional language.
- Answer in Korean
- Do not ask user for clarification.
- If the original query includes grouping or aggregation, make sure to reflect the logic accurately.
- Highlight any anomalies or low counts if the data is sparse.
'''

def parse_body(event):
    content_type = event.get("headers", {}).get("Content-Type", "") or \
                   event.get("headers", {}).get("content-type", "")
    
    raw_body = event.get("body") or ""

    if "application/json" in content_type:
        try:
            return json.loads(raw_body)
        except json.JSONDecodeError:
            print("â— ì˜ëª»ëœ JSON body:", raw_body)
            return {}
    
    elif "application/x-www-form-urlencoded" in content_type:
        return {k: v[0] for k, v in urllib.parse.parse_qs(raw_body).items()}
    
    return {}

def call_create_table_cloudtrail():
    CONFIG = get_config()
    payload = {
        "log_type": "cloudtrail",
        "s3_path": "s3://wga-cloudtrail-2/AWSLogs/339712974607/CloudTrail/us-east-1/",
        "table_name": "cloudtrail_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload) 

def call_create_table_guardduty():
    CONFIG = get_config()
    payload = {
        "log_type": "guardduty",
        "s3_path": "s3://wga-guardduty-logs/guardduty-logs/",
        "table_name": "guardduty_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload) 

def call_execute_query(sql_query):
    CONFIG = get_config()
    wrapper_payload = {
        "query": sql_query
    }
    res = requests.post(f'{CONFIG['api']['endpoint']}/execute-query', json=wrapper_payload)
    return res.json()

def send_slack_dm(user_id, message):
    CONFIG = get_config()
    client = WebClient(token=CONFIG['slackbot']['token'])
    response = client.chat_postMessage(
        channel=user_id,
        text=message
    )
    if not response["ok"]:
        print("âŒ Slack ë©”ì‹œì§€ ì‹¤íŒ¨ ì‚¬ìœ :", response["error"])
    return response

def is_ignored(text: str) -> bool:
    """LLM-1 ê²°ê³¼ê°€ ###IGNORED### ì¸ì§€ íŒì •"""
    return text.strip() == "###IGNORED###"

# 3) Insights ì¿¼ë¦¬ ìƒì„± í•¨ìˆ˜ (Log Group ë™ì  ì„ íƒ í¬í•¨)
def generate_insights_query(user_question):
    # ì‚¬ìš© ê°€ëŠ¥í•œ log group ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

    try:
        log_groups = list_log_groups()
        log_group_names = [g['logGroupName'] for g in log_groups]
    except Exception as e:
        print(f"Log groups ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"log_group": None, "query": " "}

    print(">>> ì¼ë‹¨ ë¡œê·¸ê·¸ë£¹ì€ í†µê³¼")

 
    # 3) prompt ìƒì„±
    prompt = f'''
You are an expert in generating CloudWatch Logs Insights queries.
Do NOT include any time clauses like "fromâ€¦ago" in the query itself.
Instead, decide the appropriate time window based on the user's question,
and return that as epoch milliseconds in start_time and end_time.

Available Log Groups:
{ "\n".join(log_group_names) }

User Question:
{user_question}

Return FORMAT (JSON):
{{
  "log_group": string,      # ì„ íƒëœ Log Group ì´ë¦„
  "query": string,          # ìœ íš¨í•œ Insights ì¿¼ë¦¬ (ì‹œê°„ í•„í„° ì—†ì´)
  "start_time": number,     # ì‹œì‘ ì‹œê° (epoch ì´ˆ ë‹¨ìœ„)
  "end_time": number        # ì¢…ë£Œ ì‹œê° (epoch ì´ˆ ë‹¨ìœ„)
}}

EXAMPLE:
{{
  "log_group": "/aws/lambda/wga-llm-test",
  "query": "fields @timestamp | filter detail.type = \\"Recon:EC2\\" | stats count() as threat_count by bin(1h)",
  "start_time": ì‹œì‘ì‹œê°,
  "end_time": ì¢…ë£Œì‹œê°
}}

Only output the JSONâ€”no explanations.
'''
    print(">>> prompt ê¸¸ì´:", len(prompt))

    try:
        response = invoke_bedrock_nova(prompt)
        raw = response["output"]["message"]["content"][0]["text"]
        result = json.loads(raw)
        print(">>> generate_insights_query end:", result)
        return result
    except Exception as e:
        print("âŒ generate_insights_query error:", e)
        # fallback: ê¸°ì¡´ í•˜ë“œì½”ë”© (ì§€ë‚œ 7ì¼)
        now = int(time.time() * 1000)
        week_ago = now - 7 * 24 * 3600 * 1000
        return {
            "log_group": next((g for g in log_group_names if "guardduty" in g.lower()), log_group_names[0]),
            "query": 'fields @timestamp | stats count() as threat_count',
            "start_time": week_ago,
            "end_time": now
        }

def handle_llm1_request(body, CONFIG, origin):
    user_question = body.get("text")
    slack_user_id = body.get("user_id")

    if not user_question:
        return cors_response(400, {"error": "request bodyì— 'text'ê°€ ì—†ìŒ."}, origin)

    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸: {user_question}")
    
    # í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ í™•ì¸
    registry = get_table_registry()
    print(f"í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬: {registry}")
    
    # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    classification_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì´ AWS CloudTrail ë¡œê·¸ë‚˜ GuardDuty ë¡œê·¸ì—ì„œ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì¸ì§€,
AWS ê³µì‹ ë¬¸ì„œë‚˜ ì •ë³´ë¥¼ ì°¾ì•„ë´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì¸ì§€, ì•„ë‹ˆë©´ ì•ì—ì„œ ì„¤ëª…í•œ ë‚´ìš©ê³¼ ë¬´ê´€í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì‹œì˜¤.

ê°€ëŠ¥í•œ ì‘ë‹µ:
- "QUERY": CloudTrailì´ë‚˜ GuardDuty ë¡œê·¸ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸
- "DOCUMENT": AWS ì„œë¹„ìŠ¤, ê°œë…, ê¸°ëŠ¥ ë“±ì— ëŒ€í•œ ì„¤ëª…ì´ë‚˜ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸
- "CLOUDWATCH": CloudWatch Logs Insights ì¿¼ë¦¬ë¥¼ ì§ì ‘ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸
- "USELESS": QUERY, DOCUMENT, CLOUDWATCHì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ”, ë¬´ê´€í•œ ì§ˆë¬¸

ì§ˆë¬¸: {user_question}

ì‘ë‹µ (QUERY, DOCUMENT, CLOUDWATCH, USELESSë§Œ ì‘ì„±):
"""
    
    classification_result = invoke_bedrock_nova(classification_prompt)
    decision = classification_result["output"]["message"]["content"][0]["text"].strip()
    print(f"ë¶„ë¥˜ ê²°ê³¼: {decision}")
    
    # 2ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…
    if "QUERY" in decision:
        # ê¸°ì¡´ ë¡œì§: SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
        prompt = build_llm1_prompt(user_question)
        sql_query = invoke_bedrock_nova(prompt)
        raw_text = sql_query["output"]["message"]["content"][0]["text"]

        if is_ignored(raw_text):
            cleaned_query_result = "###IGNORED###"
        else:
            cleaned = raw_text.strip().removeprefix("```sql").removesuffix("```").strip()
            call_create_table_cloudtrail()
            call_create_table_guardduty()
            cleaned_query_result = call_execute_query(cleaned)

        llm2_response = requests.post(
            f"{CONFIG['api']['endpoint']}/llm2",
            json={
                "question": user_question,
                "result": cleaned_query_result
            }
        )

        try:
            llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
            if isinstance(llm2_answer, str):
                text_answer = llm2_answer
            else:
                text_answer = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text", "[ë‹µë³€ ì—†ìŒ]")
        except Exception as parse_error:
            print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
            text_answer = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"

    elif "DOCUMENT" in decision:
        mcp_response = call_mcp_service(user_question)
        text_answer = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
    elif "CLOUDWATCH" in decision:
        # CloudWatch Logs Insights ì¿¼ë¦¬ ìƒì„±
        
        insights_result = generate_insights_query(user_question)
        
        if insights_result["query"] == "###IGNORED###" or not insights_result["log_group"]:
            text_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ë³´ì•ˆ ë¡œê·¸ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."
        else:
            try:
                # ì¿¼ë¦¬ ì‹¤í–‰ (ë™ì  log group ì‚¬ìš©)
                query_result = call_insights_query(
                    log_group=insights_result["log_group"],
                    query_string=insights_result["query"],
                    start_time=int((time.time() - 7 * 24 * 3600) * 1000),  # ì§€ë‚œ 7ì¼
                    end_time=int(time.time() * 1000)
                )
                # llm2 ì—”ë“œí¬ì¸íŠ¸ë¡œ ê²°ê³¼ ì „ì†¡ (QUERYì™€ ë™ì¼í•œ ë°©ì‹)
                llm2_response = requests.post(
                    f"{CONFIG['api']['endpoint']}/llm2",
                    json={
                        "question": user_question,
                        "result": query_result
                    }
                )
                print(">>> llm2 status:", llm2_response.status_code)
                print(">>> llm2 body:", llm2_response.text)
                try:
                    llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
                    if isinstance(llm2_answer, str):
                        text_answer = llm2_answer
                    else:
                        text_answer = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text", "[ë‹µë³€ ì—†ìŒ]")
                except Exception as parse_error:
                    print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
                    text_answer = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"
            except Exception as e:
                print(f"CloudWatch ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                text_answer = "CloudWatch ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    else:
        text_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ìš´ì˜ì •ë³´ í˜¹ì€ ë©”ë‰´ì–¼ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."

    # ìµœì¢… ê²°ê³¼ë¥¼ Slackìœ¼ë¡œ ì „ì†¡
    try:
        #send_slack_dm(slack_user_id, f"ğŸ§  ë¶„ì„ ê²°ê³¼:\n{text_answer}")
        print(1)
    except Exception as e:
        print(f"Slack ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
        text_answer += "\n(Slack ì „ì†¡ ì‹¤íŒ¨)"

    return cors_response(200, {
        "status": "ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ",
        "answer": text_answer
    }, origin)

def handle_llm2_request(body, CONFIG, origin):
    user_question = body.get("question")
    query_result = body.get("result")

    if not user_question or not query_result:
        return cors_response(400, {"error": "request bodyì— 'question' ì´ë‚˜ 'result'ê°€ ì—†ìŒ."}, origin)

    prompt = build_llm2_prompt(user_question, query_result)
    answer = invoke_bedrock_nova(prompt)
    return cors_response(200, {"answer": answer}, origin)
