import json
import urllib.parse
import requests
import boto3
import os
from datetime import datetime, timezone
from common.config import get_config
from common.utils import invoke_bedrock_nova, cors_headers, cors_response
from slack_sdk import WebClient


def get_table_registry():
    dynamodb = boto3.resource("dynamodb")
    table_name = os.environ.get("ATHENA_TABLE_REGISTRY_TABLE")
    table = dynamodb.Table(table_name)
    response = table.scan()
    return {item["log_type"]: item for item in response.get("Items", [])}


def call_mcp_service(user_question):
    CONFIG = get_config()
    payload = {
        "input": {
            "text": user_question
        }
    }
    response = requests.post(CONFIG['mcp']['function_url'], json=payload)
    return response.json()

def trans_eng_to_kor(text):
    prompt = f"""
You are a professional translator.
The following text may include a list of citations in dictionary-like format.
Translate only the explanation sentences into Korean.

- Remove any technical field names like 'rank_order', 'context', 'title', 'url'.
- Preserve any URLs and titles.
- Do NOT translate URLs or titles.
- Format the result cleanly so that each citation appears as:

í•œêµ­ì–´ ë²ˆì—­ëœ ì„¤ëª…
ì›ë˜ ì œëª©
ì›ë˜ URL

Translate the text below accordingly.
Only Generate Translate.

Text to translate:
{text}
"""
    response = invoke_bedrock_nova(prompt)
    trans_response = response["output"]["message"]["content"][0]["text"]
    return trans_response

def build_llm1_prompt(user_input):
    registry = get_table_registry()
    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
    if "cloudtrail" in registry and "guardduty" in registry:
        ct_table = registry["cloudtrail"]["table_name"]
        ct_location = registry["cloudtrail"]["s3_path"]
        gd_table = registry["guardduty"]["table_name"]
        gd_location = registry["guardduty"]["s3_path"]

        # í…Œì´ë¸” ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        tables_info = f"""
Available tables:
1. {ct_table} - CloudTrail logs at {ct_location}
2. {gd_table} - GuardDuty logs at {gd_location}
        """
    else:
        # í…Œì´ë¸” ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ê¸°ë³¸ê°’
        print("WARNING: Table registry information missing")
        tables_info = """
Available tables:
1. cloudtrail_logs - CloudTrail logs 
2. guardduty_logs - GuardDuty logs
        """

    return f'''
You are a SQL generation expert for AWS Athena (Presto SQL).
Generate ONLY SQL code that is valid in Athena with no explanation.

{tables_info}

Task:
Convert the following natural language question into an SQL query using the available tables.

Model Instructions:
    # Output Requirements:
        - Return only the SQL code, no explanations.
        - If filtering by date, use the `"partition_date"` field only.
        - If counting unique users, use `COUNT(DISTINCT userIdentity.userName)`.
        - If you use a field that is not aggregated (like username), you must include it in the GROUP BY clause.
        - Avoid using non-aggregated expressions in SELECT unless they are grouped.
        - If filtering by user name, exclude records where useridentity.username is null or empty string.
	    - Use IS NOT NULL AND useridentity.username != '' to ensure only valid user names are considered.
	    - If partition_date is a string like yyyy/MM/dd, use date_parse(partition_date, '%Y/%m/%d') to convert it before filtering by date.


User Question:
{user_input}
'''


def build_llm2_prompt(user_input, query_result):
    return f'''
You are an assistant that provides clear and accurate natural language explanations based on database query results.

Task:
Generate a human-readable answer based on the original user question and the SQL query result.

Original User Question:
{user_input}

SQL Query Result (as JSON):
{json.dumps(query_result, indent=2)}

Instructions:
- Be specific using the data.
- Use concise, professional language.
- Answer in Korean
- Do not ask user for clarification.
- If the original query includes grouping or aggregation, make sure to reflect the logic accurately.
- Highlight any anomalies or low counts if the data is sparse.
'''


def parse_body(event):
    content_type = event.get("headers", {}).get("Content-Type", "") or \
                   event.get("headers", {}).get("content-type", "")

    raw_body = event.get("body") or ""

    if "application/json" in content_type:
        try:
            return json.loads(raw_body)
        except json.JSONDecodeError:
            print("â— ì˜ëª»ëœ JSON body:", raw_body)
            return {}

    elif "application/x-www-form-urlencoded" in content_type:
        return {k: v[0] for k, v in urllib.parse.parse_qs(raw_body).items()}

    return {}


def call_create_table_cloudtrail():
    CONFIG = get_config()
    payload = {
        "log_type": "cloudtrail",
        "s3_path": "s3://wga-cloudtrail-2/AWSLogs/339712974607/CloudTrail/us-east-1/",
        "table_name": "cloudtrail_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload)


def call_create_table_guardduty():
    CONFIG = get_config()
    payload = {
        "log_type": "guardduty",
        "s3_path": "s3://wga-guardduty-logs/guardduty-logs/",
        "table_name": "guardduty_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload)


def call_execute_query(sql_query):
    CONFIG = get_config()
    wrapper_payload = {
        "query": sql_query
    }
    res = requests.post(f'{CONFIG['api']['endpoint']}/execute-query',
                        json=wrapper_payload)  # Athena ì¿¼ë¦¬ ì‹¤í–‰ API URLì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”
    return res.json()


def send_slack_dm(user_id, message):
    CONFIG = get_config()
    client = WebClient(token=CONFIG['slackbot']['token'])  # ì—¬ê¸°ì— Slack Bot Token

    response = client.chat_postMessage(
        channel=user_id,  # ì—¬ê¸°ì„œ user_id ê·¸ëŒ€ë¡œ DM ì±„ë„ë¡œ ì‚¬ìš© ê°€ëŠ¥
        text=message
    )
    if not response["ok"]:
        print("âŒ Slack ë©”ì‹œì§€ ì‹¤íŒ¨ ì‚¬ìœ :", response["error"])
    return response


def handle_llm1_request(body, CONFIG, origin):
    question_time = datetime.now(timezone.utc)
    user_question = body.get("text")
    slack_user_id = body.get("user_id")

    if not user_question:
        return cors_response(400, {"error": "request bodyì— 'text'ê°€ ì—†ìŒ."}, origin)

    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸: {user_question}")

    # í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ í™•ì¸
    registry = get_table_registry()
    print(f"í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬: {registry}")

    # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    classification_prompt = f"""
    Determine whether the following questions should be queried data from the AWS CloudTrail or GuardDuty logs, 
    look up AWS official documents or information, or are irrelevant to what was previously described.

    Possible response:
    - "QUERY":  
    Questions that request data analysis based on "CloudTrail" or "GuardDuty" logs.  
    These questions typically require SQL generation to query structured logs.  
    Example patterns:
        â€¢ Who accessed S3 yesterday?  
        â€¢ Show login failures in the last 24 hours  
        â€¢ What user deleted EC2 instances recently?  
    MUST involve:  
        - eventName, sourceIPAddress, userIdentity, region, or timestamp  
        - keywords like: find, show, list, get, analyze, from logs  

    - "DOCUMENT":  
    Questions that ask for explanations, descriptions, or definitions of AWS-related services, fields, concepts, or syntax.  
    These questions do not require data querying, but rather reference AWS documentation.  
    Example patterns:  
        â€¢ What does GuardDuty severity mean?  
        â€¢ How does partitioning work in Athena?  
        â€¢ Explain sourceIPAddress in CloudTrail  
    May include:  
        - questions starting with what / how / why / explain  
        - terminology clarification (e.g., difference between LIMIT and OFFSET)

    - "Boundary":
    Questions that are borderline between "QUERY" and "DOCUMENT".
    These questions may require both data querying and documentation reference. 

    - "USELESS":  
    Questions that are irrelevant to AWS log analysis or documentation.  
    This includes greetings, personal opinions, jokes, or off-topic inquiries.  
    Example patterns:  
        â€¢ Hello  
        â€¢ Who made you?  
        â€¢ Tell me a joke  
        â€¢ I love AWS

        
    Questions: {user_question}

    Result(QUERY, DOCUMENT, BOUNDARY, or USELESS only):
    """

    classification_result = invoke_bedrock_nova(classification_prompt)
    decision = classification_result["output"]["message"]["content"][0]["text"].strip()
    print(f"ë¶„ë¥˜ ê²°ê³¼: {decision}")

    # 2ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…
    if "QUERY" in decision:
        # ê¸°ì¡´ ë¡œì§: SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
        prompt = build_llm1_prompt(user_question)
        sql_query = invoke_bedrock_nova(prompt)
        raw_text = sql_query["output"]["message"]["content"][0]["text"]

        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
        cleaned = raw_text.strip().removeprefix("```sql").removesuffix("```").strip()

        call_create_table_cloudtrail()
        call_create_table_guardduty()
        cleaned_query_result = call_execute_query(cleaned)

        llm2_response = requests.post(
            f"{CONFIG['api']['endpoint']}/llm2",
            json={
                "question": user_question,
                "result": cleaned_query_result
            }
        )

        try:
            llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
            if isinstance(llm2_answer, str):
                text_answer = llm2_answer
            else:
                text_answer = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text",
                                                                                                           "[ë‹µë³€ ì—†ìŒ]")
        except Exception as parse_error:
            print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
            text_answer = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"

    elif "DOCUMENT" in decision:  # "DOCUMENT"ì¸ ê²½ìš°
        # MCP Lambda í˜¸ì¶œ
        mcp_response = call_mcp_service(user_question)
        text_answer = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
        text_answer = trans_eng_to_kor(text_answer)

    elif "BOUNDARY" in decision:
        # ê¸°ì¡´ ë¡œì§: SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
        prompt = build_llm1_prompt(user_question)
        sql_query = invoke_bedrock_nova(prompt)
        raw_text = sql_query["output"]["message"]["content"][0]["text"]

        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
        cleaned = raw_text.strip().removeprefix("```sql").removesuffix("```").strip()

        call_create_table_cloudtrail()
        call_create_table_guardduty()
        cleaned_query_result = call_execute_query(cleaned)

        llm2_response = requests.post(
            f"{CONFIG['api']['endpoint']}/llm2",
            json={
                "question": user_question,
                "result": cleaned_query_result
            }
        )

        try:
            llm2_answer = llm2_response.json().get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
            if isinstance(llm2_answer, str):
                text_answer_q = llm2_answer
            else:
                text_answer_q = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text",
                                                                                                           "[ë‹µë³€ ì—†ìŒ]")
        except Exception as parse_error:
            print("ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", str(parse_error))
            text_answer_q = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"

        # MCP Lambda í˜¸ì¶œ
        mcp_response = call_mcp_service(user_question)
        text_answer_d = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
        text_answer_d = trans_eng_to_kor(text_answer_d)

        text_answer = f"""
        [1] ğŸ“Š ë¡œê·¸ ë¶„ì„ ê²°ê³¼:
        {text_answer_q}

        [2] ğŸ“˜ ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ ì„¤ëª…:
        {text_answer_d}
        """
        
    else:
        text_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ìš´ì˜ì •ë³´ í˜¹ì€ ë©”ë‰´ì–¼ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."
    # ìµœì¢… ê²°ê³¼ë¥¼ Slackìœ¼ë¡œ ì „ì†¡
    # send_slack_dm(slack_user_id, f"ğŸ§  ë¶„ì„ ê²°ê³¼:\n{text_answer}")

    response_time = datetime.now(timezone.utc)
    elapsed = response_time - question_time
    minutes, seconds = divmod(elapsed.total_seconds(), 60)
    # í¬ë§·
    elapsed_str = f"{int(minutes)}ë¶„ {int(seconds)}ì´ˆ" if minutes else f"{int(seconds)}ì´ˆ"
    
    return cors_response(200, {
        "status": "ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ",
        "answer": text_answer + f"\n\nì†Œìš”ì‹œê°„: {elapsed_str}"
    }, origin)


def handle_llm2_request(body, CONFIG, origin):
    user_question = body.get("question")
    query_result = body.get("result")

    if not user_question or not query_result:
        return cors_response(400, {"error": "request bodyì— 'question' ì´ë‚˜ 'result'ê°€ ì—†ìŒ."}, origin)

    prompt = build_llm2_prompt(user_question, query_result)
    answer = invoke_bedrock_nova(prompt)

    return cors_response(200, {"answer": answer}, origin)

