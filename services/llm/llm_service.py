import json
import urllib.parse
import requests
import boto3
import os
import time
import datetime
from datetime import datetime, timezone
from common.config import get_config
from common.utils import invoke_bedrock_nova, cors_headers, cors_response
from slack_sdk import WebClient

# CloudWatch Logs client
def get_logs_client():
    return boto3.client('logs', region_name=os.environ.get('AWS_REGION'))

# 1) Log Group ëª©ë¡ ì¡°íšŒ ê¸°ëŠ¥
def list_log_groups(prefix=None, limit=50):
    """
    í˜„ì¬ ê³„ì •ì˜ CloudWatch Log Groups ëª©ë¡ì„ ë°˜í™˜
      - prefix: ì´ë¦„ ì ‘ë‘ì–´ë¡œ í•„í„°ë§ (ì—†ìœ¼ë©´ ì „ì²´)
      - limit: í˜ì´ì§€ë‹¹ ì¡°íšŒ ê°œìˆ˜
    """
    logs = get_logs_client()
    paginator = logs.get_paginator('describe_log_groups')
    params = {'limit': limit}
    if prefix:
        params['logGroupNamePrefix'] = prefix

    groups = []
    for page in paginator.paginate(**params):
        for g in page.get('logGroups', []):
            groups.append({
                'logGroupName': g['logGroupName'],
                'creationTime': g['creationTime'],
                'retentionInDays': g.get('retentionInDays')
            })
    print(f"Log groups: {groups}")
    return groups

# 2) CloudWatch Logs Insights ì¿¼ë¦¬ ê¸°ëŠ¥
def call_insights_query(log_group, query_string, start_time, end_time, limit=100):
    """
    CloudWatch Logs Insights ì¿¼ë¦¬ ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜
    """
    logs = get_logs_client()
    resp = logs.start_query(
        logGroupNames=[log_group],
        startTime=start_time,
        endTime=end_time,
        queryString=query_string,
        limit=limit
    )
    query_id = resp['queryId']

    # ì™„ë£Œ ëŒ€ê¸°
    while True:
        status_resp = logs.get_query_results(queryId=query_id)
        status = status_resp['status']
        if status in ('Complete', 'Failed', 'Cancelled'):
            print(f">>> ì¿¼ë¦¬ ìƒíƒœ: {status}")
            break
        time.sleep(1)

    results = status_resp.get('results', [])
    # Debug: raw ê²°ê³¼ ì¶œë ¥
    print(">>> call_insights_query ì›ë³¸ ê²°ê³¼:")
    print(json.dumps(results, indent=2, ensure_ascii=False))

    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì²´ ë¡œì§
    if not results:
        print(f">>> ë¹ˆ ê²°ê³¼ ")

    return results

def get_table_registry():
    dynamodb = boto3.resource("dynamodb")
    table_name = os.environ.get("ATHENA_TABLE_REGISTRY_TABLE")
    table = dynamodb.Table(table_name)
    response = table.scan()
    return {item["log_type"]: item for item in response.get("Items", [])}

def call_mcp_service(user_question):
    CONFIG = get_config()
    payload = {
        "input": {
            "text": user_question
        }
    }
    response = requests.post(CONFIG['mcp']['function_url'], json=payload)
    return response.json()

def trans_eng_to_kor(text):
    prompt = f"""
You are a professional translator.
The following text may include a list of citations in dictionary-like format.
Translate only the explanation sentences into Korean.

- Remove any technical field names like 'rank_order', 'context', 'title', 'url'.
- Preserve any URLs and titles.
- Do NOT translate URLs or titles.
- Format the result cleanly so that each citation appears as:

í•œêµ­ì–´ ë²ˆì—­ëœ ì„¤ëª…
ì›ë˜ ì œëª©
ì›ë˜ URL

Translate the text below accordingly.
Only Generate Translate.

Text to translate:
{text}
"""
    response = invoke_bedrock_nova(prompt)
    trans_response = response["output"]["message"]["content"][0]["text"]
    return trans_response


def build_llm1_prompt(user_input):
    registry = get_table_registry()
    if "cloudtrail" in registry and "guardduty" in registry:
        ct_table = registry["cloudtrail"]["table_name"]
        ct_location = registry["cloudtrail"]["s3_path"]
        gd_table = registry["guardduty"]["table_name"]
        gd_location = registry["guardduty"]["s3_path"]
        tables_info = f"""
Available tables:
1. {ct_table} - CloudTrail logs at {ct_location}
2. {gd_table} - GuardDuty logs at {gd_location}
        """
    else:
        print("WARNING: Table registry information missing")
        tables_info = """
Available tables:
1. cloudtrail_logs - CloudTrail logs 
2. guardduty_logs - GuardDuty logs
        """

    return f'''
You are a SQL generation expert for AWS Athena (Presto SQL).
Generate ONLY SQL code that is valid in Athena with no explanation.

{tables_info}

Task:
Convert the following natural language question into an SQL query using the available tables.

Decision step (MUST):
- If the request is about CloudTrail / GuardDuty / AWS ë³´ì•ˆ ë¡œê·¸ ë¶„ì„, output ONLY valid Athena SQL.
- Otherwise (greetings, DevOps ê°œë… ì„¤ëª…, ë‚ ì”¨ ë“±) output EXACTLY: ###IGNORED###

Model Instructions:
    # Output Requirements:
        - Return only the SQL code, no explanations.
        - If filtering by date, use the `"partition_date"` field only.
        - If counting unique users, use `COUNT(DISTINCT userIdentity.userName)`.
        - If you use a field that is not aggregated (like username), you must include it in the GROUP BY clause.
        - Avoid using non-aggregated expressions in SELECT unless they are grouped.
        - If filtering by user name, exclude records where useridentity.username is null or empty string.
        - Use IS NOT NULL AND useridentity.username != '' to ensure only valid user names are considered.
        - If partition_date is a string like yyyy/MM/dd, use date_parse(partition_date, '%Y/%m/%d') to convert it before filtering by date.

User Question:
{user_input}
'''

def build_llm2_prompt(user_input, query_result):
    return f'''
You are an assistant that provides clear and accurate natural language explanations based on database query results.

Task:
Generate a human-readable answer based on the original user question and the SQL query result.

# Expections(MUST):
- If the SQL query result is empty or ###IGNORED###, respond directly : "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ë³´ì•ˆ ë¡œê·¸ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."

Original User Question:
{user_input}

SQL Query Result (as JSON):
{json.dumps(query_result, indent=2)}

Instructions:
- Be specific using the data.
- Use concise, professional language.
- Answer in Korean
- Do not ask user for clarification.
- If the original query includes grouping or aggregation, make sure to reflect the logic accurately.
- Highlight any anomalies or low counts if the data is sparse.
'''

def parse_body(event):
    content_type = event.get("headers", {}).get("Content-Type", "") or \
                   event.get("headers", {}).get("content-type", "")
    
    raw_body = event.get("body") or ""

    if "application/json" in content_type:
        try:
            return json.loads(raw_body)
        except json.JSONDecodeError:
            print("â— ì˜ëª»ëœ JSON body:", raw_body)
            return {}
    
    elif "application/x-www-form-urlencoded" in content_type:
        return {k: v[0] for k, v in urllib.parse.parse_qs(raw_body).items()}
    
    return {}

def call_create_table_cloudtrail():
    CONFIG = get_config()
    payload = {
        "log_type": "cloudtrail",
        "s3_path": "s3://wga-cloudtrail-2/AWSLogs/339712974607/CloudTrail/us-east-1/",
        "table_name": "cloudtrail_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload) 

def call_create_table_guardduty():
    CONFIG = get_config()
    payload = {
        "log_type": "guardduty",
        "s3_path": "s3://wga-guardduty-logs/guardduty-logs/",
        "table_name": "guardduty_logs"
    }
    return requests.post(f'{CONFIG['api']['endpoint']}/create-table', json=payload) 

def call_execute_query(sql_query):
    CONFIG = get_config()
    wrapper_payload = {
        "query": sql_query
    }
    res = requests.post(f'{CONFIG['api']['endpoint']}/execute-query', json=wrapper_payload)
    return res.json()

def send_slack_dm(user_id, message):
    CONFIG = get_config()
    client = WebClient(token=CONFIG['slackbot']['token'])
    response = client.chat_postMessage(
        channel=user_id,
        text=message
    )
    if not response["ok"]:
        print("âŒ Slack ë©”ì‹œì§€ ì‹¤íŒ¨ ì‚¬ìœ :", response["error"])
    return response

# 3) Insights ì¿¼ë¦¬ ìƒì„± í•¨ìˆ˜ (Log Group ë™ì  ì„ íƒ í¬í•¨)
def generate_insights_query(user_question):
    # ì‚¬ìš© ê°€ëŠ¥í•œ log group ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

    try:
        log_groups = list_log_groups()
        log_group_names = [g['logGroupName'] for g in log_groups]
    except Exception as e:
        print(f"Log groups ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"log_group": None, "query": " "}

    print(">>> ì¼ë‹¨ ë¡œê·¸ê·¸ë£¹ì€ í†µê³¼")

 
    # 3) prompt ìƒì„±
    prompt = f'''
You are an expert in generating CloudWatch Logs Insights queries.
Do NOT include any time clauses like "fromâ€¦ago" in the query itself.
Instead, decide the appropriate time window based on the user's question,
and return that as epoch milliseconds in start_time and end_time.

Available Log Groups:
{ "\n".join(log_group_names) }

User Question:
{user_question}

Return FORMAT (JSON):
{{
  "log_group": string,      # ì„ íƒëœ Log Group ì´ë¦„
  "query": string,          # ìœ íš¨í•œ Insights ì¿¼ë¦¬ (ì‹œê°„ í•„í„° ì—†ì´)
  "start_time": number,     # ì‹œì‘ ì‹œê° (epoch ì´ˆ ë‹¨ìœ„)
  "end_time": number        # ì¢…ë£Œ ì‹œê° (epoch ì´ˆ ë‹¨ìœ„)
}}

EXAMPLE:
{{
  "log_group": "/aws/lambda/wga-llm-test",
  "query": "fields @timestamp | filter detail.type = \\"Recon:EC2\\" | stats count() as threat_count by bin(1h)",
  "start_time": ì‹œì‘ì‹œê°,
  "end_time": ì¢…ë£Œì‹œê°
}}

Only output the JSONâ€”no explanations.
'''
    print(">>> prompt ê¸¸ì´:", len(prompt))

    try:
        response = invoke_bedrock_nova(prompt)
        raw = response["output"]["message"]["content"][0]["text"]
        result = json.loads(raw)
        print(">>> generate_insights_query end:", result)
        return result
    except Exception as e:
        print("âŒ generate_insights_query error:", e)
        # fallback: ê¸°ì¡´ í•˜ë“œì½”ë”© (ì§€ë‚œ 7ì¼)
        now = int(time.time() * 1000)
        week_ago = now - 7 * 24 * 3600 * 1000
        return {
            "log_group": next((g for g in log_group_names if "guardduty" in g.lower()), log_group_names[0]),
            "query": 'fields @timestamp | stats count() as threat_count',
            "start_time": week_ago,
            "end_time": now
        }
def is_ignored(raw_text_sql):
    # "###IGNORED###" ë˜ëŠ” "N/A"ê°€ í¬í•¨ëœ ê²½ìš° True ë°˜í™˜
    if raw_text_sql.startswith("###IGNORED###") or raw_text_sql == "N/A":
        return True
    # ê·¸ ì™¸ì˜ ê²½ìš° False ë°˜í™˜
    return False
def handle_llm1_request(body, CONFIG, origin):
    question_time = datetime.now(timezone.utc) # ì§ˆë¬¸ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    user_question = body.get("text")
    slack_user_id = body.get("user_id")

    if not user_question:
        return cors_response(400, {"error": "request bodyì— 'text'ê°€ ì—†ìŒ."}, origin)

    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸: {user_question}")

    # í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ í™•ì¸
    registry = get_table_registry() # ì´ í•¨ìˆ˜ëŠ” common.utils ë˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    print(f"í…Œì´ë¸” ë ˆì§€ìŠ¤íŠ¸ë¦¬: {registry}")

    # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    classification_prompt = f"""
Determine whether the following questions should be queried data from the AWS CloudTrail or GuardDuty logs, 
look up AWS official documents or information, or are irrelevant to what was previously described.

Possible response:
    - "QUERY":  
    Questions that request data analysis based on "CloudTrail" or "GuardDuty" logs.  
    These questions typically require SQL generation to query structured logs.  
    Example patterns:
        â€¢ Who accessed S3 yesterday?  
        â€¢ Show login failures in the last 24 hours  
        â€¢ What user deleted EC2 instances recently?  
    MUST involve:  
        - eventName, sourceIPAddress, userIdentity, region, or timestamp  
        - keywords like: find, show, list, get, analyze, from logs  

    - "DOCUMENT":  
    Questions that ask for explanations, descriptions, or definitions of AWS-related services, fields, concepts, or syntax.  
    These questions do not require data querying, but rather reference AWS documentation.  
    Example patterns:  
        â€¢ What does GuardDuty severity mean?  
        â€¢ How does partitioning work in Athena?  
        â€¢ Explain sourceIPAddress in CloudTrail  
    May include:  
        - questions starting with what / how / why / explain  
        - terminology clarification (e.g., difference between LIMIT and OFFSET)

- "CLOUDWATCH": Questions to run CloudWatch Logs Insights query directly

- "USELESS":  
    Questions that are irrelevant to AWS log analysis or documentation.  
    This includes greetings, personal opinions, jokes, or off-topic inquiries.  
    Example patterns:  
        â€¢ Hello  
        â€¢ Who made you?  
        â€¢ Tell me a joke  
        â€¢ I love AWS

ì§ˆë¬¸: {user_question}

ì‘ë‹µ (QUERY, DOCUMENT, CLOUDWATCH, USELESSë§Œ ì‘ì„±):
"""

    classification_result = invoke_bedrock_nova(classification_prompt)
    decision = classification_result["output"]["message"]["content"][0]["text"].strip()
    print(f"ë¶„ë¥˜ ê²°ê³¼: {decision}")

    text_answer_content = ""
    response_data = {} # ìµœì¢… ì‘ë‹µ ë°ì´í„°ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬

    # 2ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…
    if "QUERY" in decision:
        prompt = build_llm1_prompt(user_question) # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        sql_query_response = invoke_bedrock_nova(prompt)
        raw_text_sql = sql_query_response["output"]["message"]["content"][0]["text"]
        cleaned_sql_query = ""
        query_execution_result = "###IGNORED###" # ê¸°ë³¸ê°’ ì„¤ì •

        if is_ignored(raw_text_sql): # is_ignored í•¨ìˆ˜ í•„ìš”
            query_execution_result = "###IGNORED###"
            text_answer_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì§ˆë¬¸ì— ëŒ€í•œ SQL ì¿¼ë¦¬ ìƒì„±ì´ ì ì ˆí•˜ì§€ ì•Šì•„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            cleaned_sql_query = "N/A (ìƒì„±ë˜ì§€ ì•ŠìŒ)"
        else:
            cleaned_sql_query = raw_text_sql.strip().removeprefix("```sql").removesuffix("```").strip()
            call_create_table_cloudtrail() # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            call_create_table_guardduty() # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            query_execution_result = call_execute_query(cleaned_sql_query) # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        
        # ì¿¼ë¦¬ ê²°ê³¼ê°€ IGNOREDê°€ ì•„ë‹ ë•Œë§Œ LLM2 í˜¸ì¶œ
        if query_execution_result != "###IGNORED###":
            llm2_response = requests.post(
                f"{CONFIG['api']['endpoint']}/llm2",
                json={
                    "question": user_question,
                    "result": query_execution_result
                }
            )
            try:
                llm2_answer_json = llm2_response.json()
                llm2_answer = llm2_answer_json.get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
                if isinstance(llm2_answer, str):
                    text_answer_content = llm2_answer
                else:
                    text_answer_content = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text", "[ë‹µë³€ ì—†ìŒ]")
            except Exception as parse_error:
                print("LLM2 ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (QUERY):", str(parse_error))
                text_answer_content = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"
        
        response_data = {
            "answer": text_answer_content,
            "query_string": cleaned_sql_query,
            "query_result": query_execution_result
        }

    elif "DOCUMENT" in decision:
        mcp_response = call_mcp_service(user_question) # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        text_answer_content = mcp_response.get("result", "[MCP ì‘ë‹µ ì—†ìŒ]")
        # ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë³´í†µ ë²ˆì—­ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¸°ì¡´ ë¡œì§ì— trans_eng_to_korê°€ ìˆë‹¤ë©´ ì‚¬ìš©)
        # text_answer_content = trans_eng_to_kor(text_answer_content) # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
        response_data = {"answer": text_answer_content}

    elif "CLOUDWATCH" in decision:
        insights_generation_result = generate_insights_query(user_question) # ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        insights_query_string = insights_generation_result.get("query", "###IGNORED###")
        log_group_name = insights_generation_result.get("log_group")
        query_execution_result = None

        if insights_query_string == "###IGNORED###" or not log_group_name:
            text_answer_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ë³´ì•ˆ ë¡œê·¸ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."
            response_data = {
                "answer": text_answer_content,
                "query_string": "N/A (ìƒì„±ë˜ì§€ ì•ŠìŒ)",
                "query_result": "N/A (ì‹¤í–‰ë˜ì§€ ì•ŠìŒ)"
            }
        else:
            try:# ì´ í•¨ìˆ˜ëŠ” llm_service ë‚´ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
                query_execution_result = call_insights_query( 
                    log_group=log_group_name,
                    query_string=insights_query_string,
                    start_time=int((time.time() - 7 * 24 * 3600) * 1000),  # ì§€ë‚œ 7ì¼
                    end_time=int(time.time() * 1000)
                )
                query_list = []
                for result in query_execution_result:
                    query_list.append({item['field']: item['value'] for item in result})
                print(">>> ì¿¼ë¦¬ ê²°ê³¼:", query_list)
                llm2_response = requests.post(
                    f"{CONFIG['api']['endpoint']}/llm2",
                    json={
                        "question": user_question,
                        "result": query_execution_result
                    }
                )
                print(">>> llm2 status (CLOUDWATCH):", llm2_response.status_code)
                print(">>> llm2 body (CLOUDWATCH):", llm2_response.text)
                try:
                    llm2_answer_json = llm2_response.json()
                    llm2_answer = llm2_answer_json.get("answer", "[ë‹µë³€ ìƒì„± ì‹¤íŒ¨]")
                    if isinstance(llm2_answer, str):
                        text_answer_content = llm2_answer
                    else:
                        text_answer_content = llm2_answer.get("output", {}).get("message", {}).get("content", [{}])[0].get("text", "[ë‹µë³€ ì—†ìŒ]")
                except Exception as parse_error:
                    print("LLM2 ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (CLOUDWATCH):", str(parse_error))
                    text_answer_content = "[ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨]"
            except Exception as e:
                print(f"CloudWatch ì¿¼ë¦¬ ì‹¤í–‰ ë˜ëŠ” LLM2 í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                text_answer_content = "CloudWatch ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ query_resultëŠ” Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬
            
            response_data = {
                "answer": text_answer_content,
                "query_string": insights_query_string, 
                "query_result": query_list
            }
    else: # USELESS ë˜ëŠ” ê¸°íƒ€
        text_answer_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ AWS ìš´ì˜ì •ë³´ í˜¹ì€ ë©”ë‰´ì–¼ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."
        response_data = {"answer": text_answer_content}

    # ìµœì¢… ê²°ê³¼ë¥¼ Slackìœ¼ë¡œ ì „ì†¡ (ì£¼ì„ ì²˜ë¦¬ëœ ë¶€ë¶„)
    # try:
    #     #send_slack_dm(slack_user_id, f"ğŸ§  ë¶„ì„ ê²°ê³¼:\n{text_answer_content}")
    #     print(1)
    # except Exception as e:
    #     print(f"Slack ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
    #     # text_answer_content += "\n(Slack ì „ì†¡ ì‹¤íŒ¨)" # í•„ìš”ì— ë”°ë¼ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€

    response_time = datetime.now(timezone.utc) # ì‘ë‹µ ìƒì„± ì‹œê°„
    elapsed = response_time - question_time
    minutes, seconds = divmod(elapsed.total_seconds(), 60)
    elapsed_str = f"{int(minutes)}ë¶„ {int(seconds)}ì´ˆ" if minutes else f"{int(seconds)}ì´ˆ"

    # response_dataì— ì†Œìš” ì‹œê°„ ì¶”ê°€
    response_data["elapsed_time"] = elapsed_str
    # "status"ëŠ” ì¼ê´€ì„±ì„ ìœ„í•´ ìµœìƒìœ„ ë ˆë²¨ì— ìœ ì§€ (ê¸°ì¡´ ì½”ë“œ ë°©ì‹)
    final_response_payload = {
        "status": "ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ",
        **response_data # response_dataì˜ ëª¨ë“  í‚¤-ê°’ì„ ì—¬ê¸°ì— í¼ì³ ë„£ìŒ
    }

    return cors_response(200, final_response_payload, origin)

def handle_llm2_request(body, CONFIG, origin):
    user_question = body.get("question")
    query_result = body.get("result")

    if not user_question or not query_result:
        return cors_response(400, {"error": "request bodyì— 'question' ì´ë‚˜ 'result'ê°€ ì—†ìŒ."}, origin)

    prompt = build_llm2_prompt(user_question, query_result)
    answer = invoke_bedrock_nova(prompt)
    return cors_response(200, {"answer": answer}, origin)